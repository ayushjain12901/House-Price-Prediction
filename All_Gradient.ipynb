{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  reading csv file\n",
    "boston_dataset = pd.read_csv(\"boston.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data into pandas dataframe\n",
    "X = pd.DataFrame(boston_dataset[['crim','zn','indus','chas','nox','rm','age','dis','rad','tax','ptratio','black','lstat']], columns =['crim','zn','indus','chas','nox','rm','age','dis','rad','tax','ptratio','black','lstat'])\n",
    "Y = boston_dataset['medv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into train and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "trindex=list(X_train.index)\n",
    "teindex=list(X_test.index)\n",
    "\n",
    "# converting into array\n",
    "X_train=np.array(X_train)\n",
    "Y_train=np.array(Y_train)\n",
    "X_test=np.array(X_test)\n",
    "Y_test=np.array(Y_test)\n",
    "X_test1=X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train is:  (392, 13)\n",
      "Shape of Y_train is:  (392,)\n",
      "Shape of X_test is:  (98, 13)\n",
      "Shape of Y_test is:  (98,)\n"
     ]
    }
   ],
   "source": [
    "# printing shape of train set\n",
    "print(\"Shape of X_train is: \",X_train.shape) \n",
    "print(\"Shape of Y_train is: \",Y_train.shape)\n",
    "print(\"Shape of X_test is: \",X_test.shape)\n",
    "print(\"Shape of Y_test is: \",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating object of StandardScaler for standardization\n",
    "scaler=StandardScaler()\n",
    "# fitting object in X_train\n",
    "scaler.fit(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy=(np.ones([392,1],dtype=int))\n",
    "#concatenating 1's for intercept calculation\n",
    "X_train=np.concatenate((dummy,X_train),axis=1)\n",
    "dummy_test=(np.ones([98,1],dtype=int))\n",
    "X_test=np.concatenate((dummy_test,X_test),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Stochastic Gradient Descent\n",
      "2. Batch Gradient Descent\n",
      "3. Mini-Batch Gradient Descent\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. Stochastic Gradient Descent\")\n",
    "print(\"2. Batch Gradient Descent\")\n",
    "print(\"3. Mini-Batch Gradient Descent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your choice from above 3\n"
     ]
    }
   ],
   "source": [
    "ch=eval(input(\"\\nEnter your choice from above \"))\n",
    "epochs=350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean-Squared-Error loss\n",
    "def calculate_error(theta):\n",
    "    error=0\n",
    "    for i in range(Y_train.shape[0]):\n",
    "        error+=np.square(np.dot(theta.transpose(),X_train[i])-Y_train[i])\n",
    "    mse=error/(2*Y_train.shape[0])\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients of features\n",
    "theta=np.random.rand(14,1)\n",
    "\n",
    "# for storing updated value of theta\n",
    "temp=np.ndarray([14,1])\n",
    "\n",
    "# learning rate\n",
    "alpha=0.01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting value of mean square error is :  [141.0056075]\n",
      "reduced value of mean square error:  [7.44050495]\n"
     ]
    }
   ],
   "source": [
    "#gradient descent calculation\n",
    "if ch==1:\n",
    "    y=[]\n",
    "    for epoch in range(epochs):\n",
    "        for j in range(14):\n",
    "            dif=0\n",
    "            for i in range(Y_train.shape[0]):\n",
    "                dif+=(np.dot(theta.transpose(),X_train[i].reshape([14,1])) - Y_train[i])*X_train[i][j]\n",
    "            temp[j] = theta[j] - (alpha/392)*(add)\n",
    "            theta=temp   \n",
    "        y.append(calculate_error(theta))\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    x=np.arange(0,epochs)\n",
    "    plt.plot(x,y,color='b')\n",
    "    plt.show()\n",
    "if ch==2:\n",
    "    y=[]\n",
    "    for epoch in range(epochs):\n",
    "        for j in range(14):\n",
    "            dif=0\n",
    "            for i in range(Y_train.shape[0]):\n",
    "                dif+=(np.dot(theta.transpose(),X_train[i].reshape([14,1])) - Y_train[i])*X_train[i][j]\n",
    "            temp[j] = theta[j] - (alpha/392)*(add)\n",
    "        theta=temp\n",
    "        y.append(calculate_error(theta))\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    x=np.arange(0,epochs)\n",
    "    plt.plot(x,y,color='b')\n",
    "    plt.show()\n",
    "if ch==3:\n",
    "    y=[]\n",
    "    batch_size=10\n",
    "    batches=Y_train.shape[0]//batch_size\n",
    "    for epoch in range(epochs):\n",
    "        for j in range(14):\n",
    "            dif=0\n",
    "            for batch in range(batches):\n",
    "                for i in range(batch*batch_size,batch*batch_size+batch_size):\n",
    "                    dif+=(np.dot(theta.transpose(),X_train[i].reshape([14,1])) - Y_train[i])*X_train[i][j]\n",
    "                temp[j] = theta[j] - (alpha/batch_size)*(add)\n",
    "                theta=temp    \n",
    "        y.append(calculate_error(theta))\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    x=np.arange(0,epochs)\n",
    "    plt.plot(x,y,color='b')\n",
    "    plt.show()\n",
    "print(\"starting value of mean square error is : \",y[0])\n",
    "print(\"reduced value of mean square error: \",y[(len(y)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average percentage error in price prediction  of train set is: 15.921037168392733% \n"
     ]
    }
   ],
   "source": [
    "#calculation of average percentage error in predicted price for train set\n",
    "per=[]\n",
    "for i in range(Y_train.shape[0]):\n",
    "    temp=((np.abs((np.dot(theta.T,X_train[i].reshape(14,1)))-(Y_train[i])))/(Y_train[i]))*100\n",
    "    per.append(temp)\n",
    "avgp=sum(per)/len(per)\n",
    "print(\"average percentage error in price prediction  of train set is: {}% \".format(avgp[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average percentage error in price prediction of test set is: 15.640019892299991% \n"
     ]
    }
   ],
   "source": [
    "#calculation of average percentage error in predicted price for test set\n",
    "per1=[]\n",
    "for i in range(Y_test.shape[0]):\n",
    "    temp=((np.abs((np.dot(theta.T,X_test[i].reshape(14,1)))-(Y_test[i])))/(Y_test[i]))*100\n",
    "    per1.append(temp)\n",
    "avgp1=sum(per1)/len(per1)\n",
    "print(\"average percentage error in price prediction of test set is: {}% \".format(avgp1[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of R2 for train set is:  0.7571863869198853\n",
      "value of rmse for test set is:  3.8209178485970106\n"
     ]
    }
   ],
   "source": [
    "#calculation of R2 and Root mean square for checking performance of train set on model\n",
    "lis=[]\n",
    "for i in range(Y_train.shape[0]):\n",
    "    temp=np.dot(theta.T,X_train[i].reshape(14,1))\n",
    "    lis.append(temp[0][0])\n",
    "Y_train_pred=np.array(lis)\n",
    "\n",
    "r=r2_score(Y_train,Y_train_pred)\n",
    "print(\"value of R2 for train set is: \",r)\n",
    "rmse = (np.sqrt(mean_squared_error(Y_train,Y_train_pred)))\n",
    "print(\"value of rmse for test set is: \",rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of R2 for test set is:  0.7925148829880575\n",
      "value of rmse for test set is:  3.7595006193846623\n"
     ]
    }
   ],
   "source": [
    "#calculatiom of R2 and Root mean square error for checking performance of test set on model\n",
    "\n",
    "lis1=[]\n",
    "for i in range(Y_test.shape[0]):\n",
    "    temp=np.dot(theta.T,X_test[i].reshape(14,1))\n",
    "    lis1.append(temp[0][0])\n",
    "Y_test_pred=np.array(lis1)\n",
    "\n",
    "r1=r2_score(Y_test,Y_test_pred)\n",
    "print(\"value of R2 for test set is: \",r1)\n",
    "rmse = (np.sqrt(mean_squared_error(Y_test,Y_test_pred)))\n",
    "print(\"value of rmse for test set is: \",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('gallery.jpg',1)\n",
    "img2 = cv2.imread('hou2.jpg',1)\n",
    "img3 = cv2.imread('hou1.jog.jpg',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        crim    zn  indus  chas    nox     rm    age     dis   rad    tax  \\\n",
      "0    0.19133  22.0   5.86   0.0  0.431  5.605   70.2  7.9549   7.0  330.0   \n",
      "1    4.66883   0.0  18.10   0.0  0.713  5.976   87.9  2.5806  24.0  666.0   \n",
      "2    0.09512   0.0  12.83   0.0  0.437  6.286   45.0  4.5026   5.0  398.0   \n",
      "3    0.08244  30.0   4.93   0.0  0.428  6.481   18.5  6.1899   6.0  300.0   \n",
      "4    3.67822   0.0  18.10   0.0  0.770  5.362   96.2  2.1036  24.0  666.0   \n",
      "5    4.54192   0.0  18.10   0.0  0.770  6.398   88.0  2.5182  24.0  666.0   \n",
      "6   11.57790   0.0  18.10   0.0  0.700  5.036   97.0  1.7700  24.0  666.0   \n",
      "7    9.51363   0.0  18.10   0.0  0.713  6.728   94.1  2.4961  24.0  666.0   \n",
      "8    0.03359  75.0   2.95   0.0  0.428  7.024   15.8  5.4011   3.0  252.0   \n",
      "9    0.41238   0.0   6.20   0.0  0.504  7.163   79.9  3.2157   8.0  307.0   \n",
      "10   0.02055  85.0   0.74   0.0  0.410  6.383   35.7  9.1876   2.0  313.0   \n",
      "11   0.06211  40.0   1.25   0.0  0.429  6.490   44.4  8.7921   1.0  335.0   \n",
      "12   0.06860   0.0   2.89   0.0  0.445  7.416   62.5  3.4952   2.0  276.0   \n",
      "13  14.42080   0.0  18.10   0.0  0.740  6.461   93.3  2.0026  24.0  666.0   \n",
      "14   0.06911  45.0   3.44   0.0  0.437  6.739   30.8  6.4798   5.0  398.0   \n",
      "15   0.15098   0.0  10.01   0.0  0.547  6.021   82.6  2.7474   6.0  432.0   \n",
      "16   0.04666  80.0   1.52   0.0  0.404  7.107   36.6  7.3090   2.0  329.0   \n",
      "17   2.73397   0.0  19.58   0.0  0.871  5.597   94.9  1.5257   5.0  403.0   \n",
      "18   0.33983  22.0   5.86   0.0  0.431  6.108   34.9  8.0555   7.0  330.0   \n",
      "19   0.14030  22.0   5.86   0.0  0.431  6.487   13.0  7.3967   7.0  330.0   \n",
      "20   1.65660   0.0  19.58   0.0  0.871  6.122   97.3  1.6180   5.0  403.0   \n",
      "21   0.03615  80.0   4.95   0.0  0.411  6.630   23.4  5.1167   4.0  245.0   \n",
      "22   0.15038   0.0  25.65   0.0  0.581  5.856   97.0  1.9444   2.0  188.0   \n",
      "23  14.33370   0.0  18.10   0.0  0.614  6.229   88.0  1.9512  24.0  666.0   \n",
      "24   0.15876   0.0  10.81   0.0  0.413  5.961   17.5  5.2873   4.0  305.0   \n",
      "25   0.22969   0.0  10.59   0.0  0.489  6.326   52.5  4.3549   4.0  277.0   \n",
      "26   7.67202   0.0  18.10   0.0  0.693  5.747   98.9  1.6334  24.0  666.0   \n",
      "27  19.60910   0.0  18.10   0.0  0.671  7.313   97.9  1.3163  24.0  666.0   \n",
      "28   8.15174   0.0  18.10   0.0  0.700  5.390   98.9  1.7281  24.0  666.0   \n",
      "29   0.10574   0.0  27.74   0.0  0.609  5.983   98.8  1.8681   4.0  711.0   \n",
      "30   0.11460  20.0   6.96   0.0  0.464  6.538   58.7  3.9175   3.0  223.0   \n",
      "31  22.59710   0.0  18.10   0.0  0.700  5.000   89.5  1.5184  24.0  666.0   \n",
      "32   0.01538  90.0   3.75   0.0  0.394  7.454   34.2  6.3361   3.0  244.0   \n",
      "33   0.08199   0.0  13.92   0.0  0.437  6.009   42.3  5.5027   4.0  289.0   \n",
      "34   0.06617   0.0   3.24   0.0  0.460  5.868   25.8  5.2146   4.0  430.0   \n",
      "35   2.63548   0.0   9.90   0.0  0.544  4.973   37.8  2.5194   4.0  304.0   \n",
      "36   0.05561  70.0   2.24   0.0  0.400  7.041   10.0  7.8278   5.0  358.0   \n",
      "37   0.09266  34.0   6.09   0.0  0.433  6.495   18.4  5.4917   7.0  329.0   \n",
      "38   0.14103   0.0  13.92   0.0  0.437  5.790   58.0  6.3200   4.0  289.0   \n",
      "39  12.80230   0.0  18.10   0.0  0.740  5.854   96.6  1.8956  24.0  666.0   \n",
      "40  38.35180   0.0  18.10   0.0  0.693  5.453  100.0  1.4896  24.0  666.0   \n",
      "41   1.19294   0.0  21.89   0.0  0.624  6.326   97.7  2.2710   4.0  437.0   \n",
      "42   0.01870  85.0   4.15   0.0  0.429  6.516   27.7  8.5353   4.0  351.0   \n",
      "43   0.06076   0.0  11.93   0.0  0.573  6.976   91.0  2.1675   1.0  273.0   \n",
      "44   0.03113   0.0   4.39   0.0  0.442  6.014   48.5  8.0136   3.0  352.0   \n",
      "45   1.61282   0.0   8.14   0.0  0.538  6.096   96.9  3.7598   4.0  307.0   \n",
      "46   0.52014  20.0   3.97   0.0  0.647  8.398   91.5  2.2885   5.0  264.0   \n",
      "47   0.19073  22.0   5.86   0.0  0.431  6.718   17.5  7.8265   7.0  330.0   \n",
      "48   0.08873  21.0   5.64   0.0  0.439  5.963   45.7  6.8147   4.0  243.0   \n",
      "49   7.02259   0.0  18.10   0.0  0.718  6.006   95.3  1.8746  24.0  666.0   \n",
      "\n",
      "    ptratio   black  lstat  \n",
      "0      19.1  389.13  18.46  \n",
      "1      20.2   10.48  19.01  \n",
      "2      18.7  383.23   8.94  \n",
      "3      16.6  379.41   6.36  \n",
      "4      20.2  380.79  10.19  \n",
      "5      20.2  374.56   7.79  \n",
      "6      20.2  396.90  25.68  \n",
      "7      20.2    6.68  18.71  \n",
      "8      18.3  395.62   1.98  \n",
      "9      17.4  372.08   6.36  \n",
      "10     17.3  396.90   5.77  \n",
      "11     19.7  396.90   5.98  \n",
      "12     18.0  396.90   6.19  \n",
      "13     20.2   27.49  18.05  \n",
      "14     15.2  389.71   4.69  \n",
      "15     17.8  394.51  10.30  \n",
      "16     12.6  354.31   8.61  \n",
      "17     14.7  351.85  21.45  \n",
      "18     19.1  390.18   9.16  \n",
      "19     19.1  396.28   5.90  \n",
      "20     14.7  372.80  14.10  \n",
      "21     19.2  396.90   4.70  \n",
      "22     19.1  370.31  25.41  \n",
      "23     20.2  383.32  13.11  \n",
      "24     19.2  376.94   9.88  \n",
      "25     18.6  394.87  10.97  \n",
      "26     20.2  393.10  19.92  \n",
      "27     20.2  396.90  13.44  \n",
      "28     20.2  396.90  20.85  \n",
      "29     20.1  390.11  18.07  \n",
      "30     18.6  394.96   7.73  \n",
      "31     20.2  396.90  31.99  \n",
      "32     15.9  386.34   3.11  \n",
      "33     16.0  396.90  10.40  \n",
      "34     16.9  382.44   9.97  \n",
      "35     18.4  350.45  12.64  \n",
      "36     14.8  371.58   4.74  \n",
      "37     16.1  383.61   8.67  \n",
      "38     16.0  396.90  15.84  \n",
      "39     20.2  240.52  23.79  \n",
      "40     20.2  396.90  30.59  \n",
      "41     21.2  396.90  12.26  \n",
      "42     17.9  392.43   6.36  \n",
      "43     21.0  396.90   5.64  \n",
      "44     18.8  385.64  10.53  \n",
      "45     21.0  248.31  20.34  \n",
      "46     13.0  386.86   5.91  \n",
      "47     19.1  393.74   6.56  \n",
      "48     16.8  395.56  13.45  \n",
      "49     20.2  319.98  15.70  \n"
     ]
    }
   ],
   "source": [
    "#Predicting prices\n",
    "flag=0\n",
    "temp=X_test1[0:50]\n",
    "df=pd.DataFrame(temp,columns=['crim','zn','indus','chas','nox','rm','age','dis','rad','tax','ptratio','black','lstat'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the index no from above data for which you want to predict price: 48\n",
      "\n",
      "PREDICTED PRICE OF HOUSE IS:  21.80087986304114\n",
      "ORIGINAL PRICE OF HOUSE IS :  19.7\n",
      "\n",
      "image of your house is as below\n"
     ]
    }
   ],
   "source": [
    "ind=int(input(\"\\nEnter the index no from above data for which you want to predict price: \"))\n",
    "price=np.dot(theta.transpose(),X_test[ind].reshape(14,1))\n",
    "if(ind<20):\n",
    "    flag=1\n",
    "elif(ind>=20 and ind<=35):\n",
    "    flag=2\n",
    "else:\n",
    "    flag=3\n",
    "print(\"\\nPREDICTED PRICE OF HOUSE IS: \",price[0][0])\n",
    "print(\"ORIGINAL PRICE OF HOUSE IS : \",Y_test[ind])\n",
    "print(\"\\nimage of your house is as below\")\n",
    "if(flag==1):\n",
    "    cv2.imshow('image1',img1)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "elif(flag==2):\n",
    "    cv2.imshow('image2',img2)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "elif(flag==3):\n",
    "    cv2.imshow('image3',img3)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

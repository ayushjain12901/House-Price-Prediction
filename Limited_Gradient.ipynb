{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading csv file\n",
    "boston_dataset = pd.read_csv(\"boston.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data in pandas dataframe\n",
    "X = pd.DataFrame(boston_dataset[['rm','ptratio','black','lstat']], columns =['rm','ptratio','black','lstat'])\n",
    "Y = boston_dataset['medv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)  #splitting data into train and test set\n",
    "trindex=list(X_train.index)\n",
    "teindex=list(X_test.index)\n",
    "\n",
    "#converting into array\n",
    "X_train=np.array(X_train)\n",
    "Y_train=np.array(Y_train)\n",
    "X_test=np.array(X_test)\n",
    "Y_test=np.array(Y_test)\n",
    "X_test1=X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape of X_train is:  (392, 4)\n",
      "shape of Y_train is:  (392,)\n",
      "shape of X_test is:  (98, 4)\n",
      "shape of Y_test is:  (98,)\n"
     ]
    }
   ],
   "source": [
    "#printing shape of array\n",
    "print(\"\\nshape of X_train is: \",X_train.shape)\n",
    "print(\"shape of Y_train is: \",Y_train.shape)\n",
    "print(\"shape of X_test is: \",X_test.shape)\n",
    "print(\"shape of Y_test is: \",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating object of StandardScaler for standardization\n",
    "scaler=StandardScaler() \n",
    "\n",
    "#fitting into X_train\n",
    "scaler.fit(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy=(np.ones([392,1],dtype=int)) \n",
    "\n",
    "# concatenating 1's for intercept calculation\n",
    "X_train=np.concatenate((dummy,X_train),axis=1) \n",
    "\n",
    "dummy_test=(np.ones([98,1],dtype=int))\n",
    "\n",
    "# concatenating 1's for intercept calculation\n",
    "X_test=np.concatenate((dummy_test,X_test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Stochastic Gradient Descent\n",
      "2. Batch Gradient Descent\n",
      "3. Mini-Batch Gradient Descent\n",
      "\n",
      "Enter your choice 3\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. Stochastic Gradient Descent\")\n",
    "print(\"2. Batch Gradient Descent\")\n",
    "print(\"3. Mini-Batch Gradient Descent\")\n",
    "\n",
    "ch=eval(input(\"\\nEnter your choice \"))\n",
    "epochs=350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean-Squared-Error loss\n",
    "def calculate_error(theta):\n",
    "    error=0\n",
    "    for i in range(Y_train.shape[0]):\n",
    "        error+=np.square(np.dot(theta.transpose(),X_train[i])-Y_train[i])\n",
    "    mse=error/(2*Y_train.shape[0])\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array with random values of coefficients\n",
    "theta=np.random.rand(5,1) \n",
    "\n",
    "# array for storing updated value of theta\n",
    "temp=np.ndarray([5,1]) \n",
    "\n",
    "#learning rate\n",
    "alpha=0.0086 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial value of mean square error was:  [194.12471203]\n",
      "reduced value of mean square error is:  [8.77248557]\n"
     ]
    }
   ],
   "source": [
    "#gradient descent calculation\n",
    "if ch==1:\n",
    "    y=[]\n",
    "    for epoch in range(epochs):\n",
    "        for j in range(5):\n",
    "            dif=0\n",
    "            for i in range(Y_train.shape[0]):\n",
    "                dif+=(np.dot(theta.transpose(),X_train[i].reshape([5,1])) - Y_train[i])*X_train[i][j]\n",
    "            temp[j] = theta[j] - (alpha/392)*(dif)\n",
    "            theta=temp   \n",
    "        y.append(calculate_error(theta))\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    x=np.arange(0,epochs)\n",
    "    plt.plot(x,y,color='b')\n",
    "    plt.show()\n",
    "if ch==2:\n",
    "    y=[]\n",
    "    for epoch in range(epochs):\n",
    "        for j in range(5):\n",
    "            dif=0\n",
    "            for i in range(Y_train.shape[0]):\n",
    "                dif+=(np.dot(theta.transpose(),X_train[i].reshape([5,1])) - Y_train[i])*X_train[i][j]\n",
    "            temp[j] = theta[j] - (alpha/392)*(dif)\n",
    "        theta=temp\n",
    "        y.append(calculate_error(theta))\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    x=np.arange(0,epochs)\n",
    "    plt.plot(x,y,color='b')\n",
    "    plt.show()\n",
    "if ch==3:\n",
    "    y=[]\n",
    "    batch_size=10\n",
    "    batches=Y_train.shape[0]//batch_size\n",
    "    for epoch in range(epochs):\n",
    "        for j in range(5):\n",
    "            dif=0\n",
    "            for batch in range(batches):\n",
    "                for i in range(batch*batch_size,batch*batch_size+batch_size):\n",
    "                    dif+=(np.dot(theta.transpose(),X_train[i].reshape([5,1])) - Y_train[i])*X_train[i][j]\n",
    "                temp[j] = theta[j] - (alpha/batch_size)*(dif)\n",
    "                theta=temp    \n",
    "        y.append(calculate_error(theta))\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    x=np.arange(0,epochs)\n",
    "    plt.plot(x,y,color='b')\n",
    "    plt.show()\n",
    "print(\"initial value of mean square error was: \",y[0])\n",
    "print(\"reduced value of mean square error is: \",y[(len(y)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average percentage error in price prediction of train set is: 17.103694151816274% \n"
     ]
    }
   ],
   "source": [
    "#calculation of average percentage error in predicted price for train set\n",
    "per=[]\n",
    "for i in range(Y_train.shape[0]):\n",
    "    temp=((np.abs((np.dot(theta.T,X_train[i].reshape(5,1)))-(Y_train[i])))/(Y_train[i]))*100\n",
    "    per.append(temp)\n",
    "avgp=sum(per)/len(per)\n",
    "print(\"average percentage error in price prediction of train set is: {}% \".format(avgp[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average percentage error in price prediction of test set is: 16.437665748561386% \n"
     ]
    }
   ],
   "source": [
    "#calculation of average percentage error in predicted price for test set\n",
    "per1=[]\n",
    "for i in range(Y_test.shape[0]):\n",
    "    temp=((np.abs((np.dot(theta.T,X_test[i].reshape(5,1)))-(Y_test[i])))/(Y_test[i]))*100\n",
    "    per1.append(temp)\n",
    "avgp1=sum(per1)/len(per1)\n",
    "print(\"average percentage error in price prediction of test set is: {}% \".format(avgp1[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation of R2 and root mean square error for checking performance of train set\n",
    "lis=[]\n",
    "for i in range(Y_train.shape[0]):\n",
    "    temp=np.sum(np.dot(theta.T,X_train[i].reshape(5,1)))\n",
    "    lis.append(temp)\n",
    "Y_train_pred=np.array(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of R2 for train set is:  0.70819663967519\n",
      "RMSE value is:  4.188671762390509\n"
     ]
    }
   ],
   "source": [
    "r=r2_score(Y_train,Y_train_pred)\n",
    "print(\"value of R2 for train set is: \",r)\n",
    "rmse = (np.sqrt(mean_squared_error(Y_train,Y_train_pred)))\n",
    "print(\"RMSE value is: \",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation of R2 and root mean square error for checking performance of test set\n",
    "lis1=[]\n",
    "for i in range(Y_test.shape[0]):\n",
    "    temp=np.sum(np.dot(theta.T,X_test[i].reshape(5,1)))\n",
    "    lis1.append(temp)\n",
    "Y_test_pred=np.array(lis1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of R2 for test set is :  0.7562994151482868\n",
      "value of rmse for test set is :  4.07441227344886\n"
     ]
    }
   ],
   "source": [
    "r1=r2_score(Y_test,Y_test_pred)\n",
    "print(\"value of R2 for test set is : \",r1)\n",
    "rmse = (np.sqrt(mean_squared_error(Y_test,Y_test_pred)))\n",
    "print(\"value of rmse for test set is : \",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img1 = cv2.imread('gallery.jpg',1)\n",
    "img2 = cv2.imread('hou2.jpg',1)\n",
    "img3 = cv2.imread('hou1.jog.jpg',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       rm  ptratio   black  lstat\n",
      "0   5.605     19.1  389.13  18.46\n",
      "1   5.976     20.2   10.48  19.01\n",
      "2   6.286     18.7  383.23   8.94\n",
      "3   6.481     16.6  379.41   6.36\n",
      "4   5.362     20.2  380.79  10.19\n",
      "5   6.398     20.2  374.56   7.79\n",
      "6   5.036     20.2  396.90  25.68\n",
      "7   6.728     20.2    6.68  18.71\n",
      "8   7.024     18.3  395.62   1.98\n",
      "9   7.163     17.4  372.08   6.36\n",
      "10  6.383     17.3  396.90   5.77\n",
      "11  6.490     19.7  396.90   5.98\n",
      "12  7.416     18.0  396.90   6.19\n",
      "13  6.461     20.2   27.49  18.05\n",
      "14  6.739     15.2  389.71   4.69\n",
      "15  6.021     17.8  394.51  10.30\n",
      "16  7.107     12.6  354.31   8.61\n",
      "17  5.597     14.7  351.85  21.45\n",
      "18  6.108     19.1  390.18   9.16\n",
      "19  6.487     19.1  396.28   5.90\n",
      "20  6.122     14.7  372.80  14.10\n",
      "21  6.630     19.2  396.90   4.70\n",
      "22  5.856     19.1  370.31  25.41\n",
      "23  6.229     20.2  383.32  13.11\n",
      "24  5.961     19.2  376.94   9.88\n",
      "25  6.326     18.6  394.87  10.97\n",
      "26  5.747     20.2  393.10  19.92\n",
      "27  7.313     20.2  396.90  13.44\n",
      "28  5.390     20.2  396.90  20.85\n",
      "29  5.983     20.1  390.11  18.07\n",
      "30  6.538     18.6  394.96   7.73\n",
      "31  5.000     20.2  396.90  31.99\n",
      "32  7.454     15.9  386.34   3.11\n",
      "33  6.009     16.0  396.90  10.40\n",
      "34  5.868     16.9  382.44   9.97\n",
      "35  4.973     18.4  350.45  12.64\n",
      "36  7.041     14.8  371.58   4.74\n",
      "37  6.495     16.1  383.61   8.67\n",
      "38  5.790     16.0  396.90  15.84\n",
      "39  5.854     20.2  240.52  23.79\n",
      "40  5.453     20.2  396.90  30.59\n",
      "41  6.326     21.2  396.90  12.26\n",
      "42  6.516     17.9  392.43   6.36\n",
      "43  6.976     21.0  396.90   5.64\n",
      "44  6.014     18.8  385.64  10.53\n",
      "45  6.096     21.0  248.31  20.34\n",
      "46  8.398     13.0  386.86   5.91\n",
      "47  6.718     19.1  393.74   6.56\n",
      "48  5.963     16.8  395.56  13.45\n",
      "49  6.006     20.2  319.98  15.70\n",
      "\n",
      "enter the index no from above data for which you want to predict price: 11\n",
      "\n",
      "PREDICTED PRICE OF HOUSE IS:  25.375976264538785\n",
      "ORIGINAL PRICE OF HOUSE IS :  22.9\n",
      "\n",
      "image of your house is as below\n"
     ]
    }
   ],
   "source": [
    "#Predicting prices\n",
    "flag=0\n",
    "temp=X_test1[0:50]\n",
    "df=pd.DataFrame(temp,columns=['rm','ptratio','black','lstat'])\n",
    "print(df)\n",
    "\n",
    "ind=int(input(\"\\nenter the index no from above data for which you want to predict price: \"))\n",
    "price=np.dot(theta.transpose(),X_test[ind].reshape(5,1))\n",
    "if(ind<20):\n",
    "    flag=1\n",
    "elif(ind>=20 and ind<=35):\n",
    "    flag=2\n",
    "else:\n",
    "    flag=3\n",
    "print(\"\\nPREDICTED PRICE OF HOUSE IS: \",price[0][0])\n",
    "print(\"ORIGINAL PRICE OF HOUSE IS : \",Y_test[ind])\n",
    "print(\"\\nimage of your house is as below\")\n",
    "\n",
    "    \n",
    "if(flag==1):\n",
    "    cv2.imshow('image1',img1)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "elif(flag==2):\n",
    "    cv2.imshow('image2',img2)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "elif(flag==3):\n",
    "    cv2.imshow('image3',img3)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
